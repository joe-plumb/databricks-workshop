{"cells":[{"cell_type":"markdown","source":["## Quick Start Using Python\n* Using a Databricks notebook to showcase RDD operations using Python\n* Reference http://spark.apache.org/docs/latest/quick-start.html"],"metadata":{}},{"cell_type":"code","source":["# Take a look at the file system\ndisplay(dbutils.fs.ls(\"/databricks-datasets/samples/docs/\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/samples/docs/README.md</td><td>README.md</td><td>3137</td></tr></tbody></table></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Setup the textFile RDD to read the README.md file\n#   Note this is lazy \ntextFile = sc.textFile(\"/databricks-datasets/samples/docs/README.md\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["RDDs have ***actions***, which return values, and ***transformations***, which return pointers to new RDDs."],"metadata":{}},{"cell_type":"code","source":["# When performing an action (like a count) this is when the textFile is read and aggregate calculated\n#    Click on [View] to see the stages and executors\ntextFile.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">3</span><span class=\"ansired\">]: </span>65\n</div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["## Python Count (Job)\n![Python Count - Job](https://sparkhub.databricks.com/wp-content/uploads/2015/12/Python-Count-Job.png)"],"metadata":{}},{"cell_type":"markdown","source":["## Python Count (Stages)\n* Notice how the file is read during the *.count()* action\n* Many Spark operations are lazy and executed upon some action\n\n![Python Count - Stages](https://sparkhub.databricks.com/wp-content/uploads/2015/12/Python-Count-Stages.png)"],"metadata":{}},{"cell_type":"code","source":["# Output the first line from the text file\ntextFile.first()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">4</span><span class=\"ansired\">]: </span>&apos;Welcome to the Spark documentation!&apos;\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["Now we're using a filter ***transformation*** to return a new RDD with a subset of the items in the file."],"metadata":{}},{"cell_type":"code","source":["# Filter all of the lines wihtin the RDD and output the first five rows\nlinesWithSpark = textFile.filter(lambda line: \"Spark\" in line)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["Notice that this completes quickly because it is a transformation but lacks any action.  \n* But when performing the actions below (e.g. count, take) then you will see the executions."],"metadata":{}},{"cell_type":"code","source":["# Perform a count (action) \nlinesWithSpark.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>12\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["# Filter all of the lines within the RDD and output the first five rows\nlinesWithSpark.take(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>\n[&apos;Welcome to the Spark documentation!&apos;,\n &apos;This readme will walk you through navigating and building the Spark documentation, which is included&apos;,\n &apos;here with the Spark source code. You can also find documentation specific to release versions of&apos;,\n &apos;Spark at http://spark.apache.org/documentation.html.&apos;,\n &apos;whichever version of Spark you currently have checked out of revision control.&apos;]\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"Lab2 - Quick Start Using Python","notebookId":220615615376392},"nbformat":4,"nbformat_minor":0}
